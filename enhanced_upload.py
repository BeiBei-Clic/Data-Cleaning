import os
import glob
import time
import requests
from pathlib import Path
from origin import (
    check_environment_variables,
    create_client,
    calculate_md5,
    get_file_size,
    apply_lease,
    upload_file,
    add_file,
    describe_file,
    get_index_job_status,
    submit_index_add_documents_job,
)
from dotenv import load_dotenv
from openai import OpenAI

load_dotenv()

class EnhancedUploader:
    def __init__(self):
        # å¤§æ¨¡å‹é…ç½®
        self.client = OpenAI(
            api_key=os.getenv('OPENROUTER_API_KEY'),
            base_url=os.getenv('OPENROUTER_BASE_URL')
        )
        self.model = 'google/gemini-2.5-flash'
        
        # minerU APIé…ç½®
        self.mineru_token = os.getenv('MINERU_API_TOKEN', "å®˜ç½‘ç”³è¯·çš„api token")
        self.mineru_base_url = "https://mineru.net/api/v4"
        
        # æ–‡æœ¬å¤„ç†å‚æ•°
        self.chunk_size = 20000
        self.overlap_size = 1000
        self.max_retries = 3
    
    def read_file(self, file_path: str) -> str:
        """ä½¿ç”¨minerU APIè¯»å–å¹¶è§£ææ–‡æ¡£å†…å®¹ï¼Œè¿”å›markdownæ ¼å¼"""
        path = Path(file_path)
        ext = path.suffix.lower()
        
        # å¯¹äºçº¯æ–‡æœ¬æ–‡ä»¶ï¼Œç›´æ¥è¯»å–
        if ext in ['.txt', '.md']:
            with open(path, 'r', encoding='utf-8') as f:
                return f.read()
        
        # å¯¹äºPDFã€DOCXç­‰æ–‡æ¡£ï¼Œä½¿ç”¨minerU APIè§£æ
        if ext in ['.pdf', '.docx', '.doc', '.ppt', '.pptx']:
            return self._parse_with_mineru(file_path)
        
        # å…¶ä»–æ ¼å¼å°è¯•ç›´æ¥è¯»å–
        with open(path, 'r', encoding='utf-8') as f:
            return f.read()
    
    def _parse_with_mineru(self, file_path: str) -> str:
        """ä½¿ç”¨minerU APIè§£ææ–‡æ¡£"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.mineru_token}"
        }
        
        # 1. ç”³è¯·ä¸Šä¼ URL
        file_name = os.path.basename(file_path)
        upload_data = {
            "enable_formula": True,
            "language": "ch",
            "enable_table": True,
            "files": [
                {"name": file_name, "is_ocr": True, "data_id": file_name}
            ]
        }
        
        response = requests.post(
            f"{self.mineru_base_url}/file-urls/batch",
            headers=headers,
            json=upload_data
        )
        
        if response.status_code != 200:
            print(f"ç”³è¯·ä¸Šä¼ URLå¤±è´¥: {response.status_code}")
            return ""
        
        result = response.json()
        if result["code"] != 0:
            print(f"ç”³è¯·ä¸Šä¼ URLå¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
            return ""
        
        batch_id = result["data"]["batch_id"]
        upload_url = result["data"]["file_urls"][0]
        
        # 2. ä¸Šä¼ æ–‡ä»¶
        with open(file_path, 'rb') as f:
            upload_response = requests.put(upload_url, data=f)
            if upload_response.status_code != 200:
                print(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {upload_response.status_code}")
                return ""
        
        print(f"æ–‡ä»¶ {file_name} ä¸Šä¼ æˆåŠŸï¼Œå¼€å§‹è§£æ...")
        
        # 3. ç­‰å¾…è§£æå®Œæˆå¹¶è·å–ç»“æœ
        max_wait_time = 300  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
        wait_time = 0
        
        while wait_time < max_wait_time:
            time.sleep(10)
            wait_time += 10
            
            # æŸ¥è¯¢è§£æç»“æœ
            result_response = requests.get(
                f"{self.mineru_base_url}/extract-results/batch/{batch_id}",
                headers=headers
            )
            
            if result_response.status_code == 200:
                result_data = result_response.json()
                if result_data["code"] == 0:
                    data = result_data["data"]
                    if data and len(data) > 0:
                        # è·å–ç¬¬ä¸€ä¸ªæ–‡ä»¶çš„è§£æç»“æœ
                        file_result = data[0]
                        if "md_content" in file_result:
                            print(f"æ–‡ä»¶ {file_name} è§£æå®Œæˆ")
                            return file_result["md_content"]
                        elif "status" in file_result and file_result["status"] == "failed":
                            print(f"æ–‡ä»¶ {file_name} è§£æå¤±è´¥")
                            return ""
            
            print(f"ç­‰å¾…è§£æå®Œæˆ... ({wait_time}s)")
        
        print(f"æ–‡ä»¶ {file_name} è§£æè¶…æ—¶")
        return ""
    
    def generate_summary(self, text: str, filename: str) -> str:
        """ç”Ÿæˆæ‘˜è¦ï¼ˆé‡‡ç”¨åˆ†å—æ¸…æ´—ç›¸åŒçš„åˆ†å—é€»è¾‘ï¼‰"""
        CHUNK_SIZE = self.chunk_size
        OVERLAP_SIZE = self.overlap_size

        prompt_template = """è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å…³é”®ä¿¡æ¯ä½œä¸ºéƒ¨åˆ†æ‘˜è¦ï¼š

å½“å‰æ–‡æ¡£: {filename}
åˆ†å—: {chunk_num}/{total_chunks}

è¦æ±‚ï¼š
1. æå–æœ¬éƒ¨åˆ†çš„æ ¸å¿ƒå†…å®¹
2. ä¿æŒå®¢è§‚äº‹å®
3. ç”¨ç®€æ´çš„çŸ­è¯­åˆ—å‡ºè¦ç‚¹

æ–‡æœ¬å†…å®¹ï¼š
{chunk_text}"""

        final_prompt = """è¯·å°†ä»¥ä¸‹éƒ¨åˆ†æ‘˜è¦åˆå¹¶ä¸ºå®Œæ•´æ‘˜è¦ï¼ŒæŒ‰ç»“æ„æ•´ç†ï¼š

ã€æ ‡é¢˜ã€‘<ä¿æŒåŸæ–‡æ ‡é¢˜ä¸å˜>

- é¡¹ç›®èƒŒæ™¯ï¼ˆæ•´åˆå„éƒ¨åˆ†èƒŒæ™¯ï¼‰
- ä¸»è¦æªæ–½ï¼ˆåˆå¹¶æ‰€æœ‰æªæ–½ï¼Œå»é‡åä¿ç•™3-5ç‚¹ï¼‰
- å–å¾—æˆæ•ˆï¼ˆåˆå¹¶é‡åŒ–æˆæœï¼‰
- ç»éªŒæ•™è®­ï¼ˆæ•´åˆå…³é”®ç»éªŒï¼‰

è¦æ±‚ï¼šæœ€ç»ˆæ‘˜è¦ä¸è¶…è¿‡600å­—

éƒ¨åˆ†æ‘˜è¦ï¼š
{partial_summaries}"""

        # åˆ†å—é€»è¾‘
        def split_into_chunks(text: str) -> list:
            if len(text) <= CHUNK_SIZE:
                return [text]

            chunks = []
            start = 0
            while start < len(text):
                end = start + CHUNK_SIZE
                if end < len(text):
                    for separator in ['\n\n', 'ã€‚', '\n', ' ']:
                        search_start = max(start + CHUNK_SIZE - OVERLAP_SIZE, start)
                        split_pos = text.rfind(separator, search_start, end)
                        if split_pos != -1:
                            end = split_pos + len(separator)
                            break
                chunks.append(text[start:end].strip())
                start = max(end - OVERLAP_SIZE, start + 1)
            return chunks

        # å¤„ç†å•ä¸ªåˆ†å—
        def process_chunk(chunk: str, chunk_num: int, total_chunks: int) -> str:
            prompt = prompt_template.format(
                filename=filename,
                chunk_num=chunk_num + 1,
                total_chunks=total_chunks,
                chunk_text=chunk
            )

            for attempt in range(self.max_retries):
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.3,
                    max_tokens=300
                )
                if response and response.choices:
                    return response.choices[0].message.content
                if attempt < self.max_retries - 1:
                    time.sleep(30)
            return f"[åˆ†å—{chunk_num + 1}æ‘˜è¦ç”Ÿæˆå¤±è´¥]"

        # ä¸»æµç¨‹
        chunks = split_into_chunks(text)
        if len(chunks) == 1:
            # å°æ–‡ä»¶ç›´æ¥å¤„ç†
            prompt = f"""è¯·ä»ä»¥ä¸‹æ¡ˆä¾‹ä¸­æå–å…³é”®ä¿¡æ¯ï¼ŒæŒ‰ä»¥ä¸‹ç»“æ„æ€»ç»“ï¼š

ã€æ ‡é¢˜ã€‘<ä¿æŒåŸæ–‡æ ‡é¢˜ä¸å˜>

- é¡¹ç›®èƒŒæ™¯
- ä¸»è¦æªæ–½ï¼ˆ3-5ç‚¹ï¼‰
- å–å¾—æˆæ•ˆï¼ˆ2-3é¡¹å…·ä½“æˆæœï¼‰
- ç»éªŒæ•™è®­ï¼ˆ3-5ç‚¹ï¼‰

è¦æ±‚ï¼šå­—æ•°ä¸è¶…è¿‡600å­—

æ¡ˆä¾‹[{filename}]ï¼š
{text}"""
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3
            )
            return response.choices[0].message.content

        # å¤§æ–‡ä»¶åˆ†å—å¤„ç†
        print(f"ğŸ“‘ å¤§æ–‡ä»¶åˆ†å—å¤„ç†: {filename} (å…±{len(chunks)}å—)")

        partial_summaries = []
        for i, chunk in enumerate(chunks):
            print(f"  æ­£åœ¨å¤„ç†åˆ†å— {i + 1}/{len(chunks)}...")
            chunk_summary = process_chunk(chunk, i, len(chunks))
            partial_summaries.append(f"=== åˆ†å— {i + 1} ===\n{chunk_summary}")

        # åˆå¹¶æ‘˜è¦
        print("ğŸ”„ åˆå¹¶éƒ¨åˆ†æ‘˜è¦...")
        combined_text = "\n\n".join(partial_summaries)
        final_response = self.client.chat.completions.create(
            model=self.model,
            messages=[{"role": "user", "content": final_prompt.format(partial_summaries=combined_text)}],
            temperature=0.3,
            max_tokens=600
        )
        return final_response.choices[0].message.content
    
    def upload_file_to_knowledge_base(self, file_path: str, workspace_id: str, index_id: str) -> str:
        """ä¸Šä¼ æ–‡ä»¶åˆ°çŸ¥è¯†åº“å¹¶è¿”å›æ–‡æ¡£ID"""
        client = create_client()
        
        file_name = os.path.basename(file_path)
        file_md5 = calculate_md5(file_path)
        file_size = get_file_size(file_path)
        
        # ç”³è¯·ä¸Šä¼ ç§Ÿçº¦
        lease_response = apply_lease(client, 'default', file_name, file_md5, file_size, workspace_id)
        lease_id = lease_response.body.data.file_upload_lease_id
        upload_url = lease_response.body.data.param.url
        upload_headers = lease_response.body.data.param.headers
        
        # ä¸Šä¼ æ–‡ä»¶
        upload_file(upload_url, upload_headers, file_path)
        
        # æ·»åŠ æ–‡ä»¶åˆ°æœåŠ¡å™¨
        add_response = add_file(client, lease_id, 'DASHSCOPE_DOCMIND', 'default', workspace_id)
        file_id = add_response.body.data.file_id
        
        # ç­‰å¾…æ–‡ä»¶è§£æå®Œæˆ
        while True:
            describe_response = describe_file(client, workspace_id, file_id)
            status = describe_response.body.data.status
            print(f"æ–‡ä»¶ {file_name} çŠ¶æ€ï¼š{status}")
            
            if status == 'PARSE_SUCCESS':
                print(f"æ–‡ä»¶ {file_name} è§£æå®Œæˆï¼")
                break
            elif status in ['INIT', 'PARSING']:
                time.sleep(5)
            else:
                print(f"æ–‡ä»¶ {file_name} è§£æå¤±è´¥ï¼ŒçŠ¶æ€ï¼š{status}")
                return None
        
        # å‘çŸ¥è¯†åº“æ·»åŠ æ–‡æ¡£
        add_response = submit_index_add_documents_job(client, workspace_id, index_id, file_id, 'DATA_CENTER_FILE')
        if add_response.status_code == 200:
            job_id = add_response.body.data.id
            print(f"æ–‡æ¡£ {file_id} æ·»åŠ ä»»åŠ¡å·²æäº¤ï¼Œä»»åŠ¡ID: {job_id}")
            
            # ç­‰å¾…ä»»åŠ¡å®Œæˆ
            while True:
                job_status = get_index_job_status(client, workspace_id, index_id, job_id)
                status = job_status.body.data.status
                if status == "COMPLETED":
                    print(f"æ–‡æ¡£ {file_id} æ·»åŠ å®Œæˆ")
                    return file_id
                elif status == "FAILED":
                    print(f"æ–‡æ¡£ {file_id} æ·»åŠ å¤±è´¥")
                    return None
                time.sleep(10)
        
        return None
    
    def upload_summary_to_knowledge_base(self, summary: str, doc_id: str, workspace_id: str, index_id: str) -> bool:
        """å°†æ‘˜è¦ä¸Šä¼ åˆ°æ‘˜è¦çŸ¥è¯†åº“"""
        # åˆ›å»ºä¸´æ—¶æ‘˜è¦æ–‡ä»¶
        temp_summary_path = f"{doc_id}.md"
        with open(temp_summary_path, 'w', encoding='utf-8') as f:
            f.write(summary)
        
        # ä¸Šä¼ æ‘˜è¦æ–‡ä»¶
        summary_doc_id = self.upload_file_to_knowledge_base(temp_summary_path, workspace_id, index_id)
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(temp_summary_path)
        
        return summary_doc_id is not None
    
    def batch_upload_with_summary(self, directory_path: str, workspace_id: str, original_index_id: str, summary_index_id: str):
        """æ‰¹é‡ä¸Šä¼ æ–‡æ¡£å¹¶ç”Ÿæˆæ‘˜è¦"""
        if not check_environment_variables():
            return {"error": "ç¯å¢ƒå˜é‡æœªæ­£ç¡®è®¾ç½®"}
        
        # è·å–æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        supported_extensions = ['*.pdf', '*.docx', '*.doc', '*.md', '*.txt']
        all_files = []
        for ext in supported_extensions:
            all_files.extend(glob.glob(os.path.join(directory_path, ext)))
        
        if not all_files:
            return {"error": "æœªæ‰¾åˆ°æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"}
        
        print(f"æ‰¾åˆ° {len(all_files)} ä¸ªæ”¯æŒçš„æ–‡ä»¶")
        
        results = []
        
        for file_path in all_files:
            file_name = os.path.basename(file_path)
            print(f"\næ­£åœ¨å¤„ç†æ–‡ä»¶: {file_name}")
            
            # 1. è¯»å–æ–‡ä»¶å†…å®¹
            print("ğŸ“– è¯»å–æ–‡ä»¶å†…å®¹...")
            text = self.read_file(file_path)
            
            # 2. ç”Ÿæˆæ‘˜è¦
            print("ğŸ“ ç”Ÿæˆæ‘˜è¦...")
            summary = self.generate_summary(text, file_name)
            
            # 3. ä¸Šä¼ åŸæ–‡åˆ°çŸ¥è¯†åº“1
            print("ğŸ“¤ ä¸Šä¼ åŸæ–‡åˆ°åŸæ–‡çŸ¥è¯†åº“...")
            doc_id = self.upload_file_to_knowledge_base(file_path, workspace_id, original_index_id)
            
            if doc_id:
                # 4. ä¸Šä¼ æ‘˜è¦åˆ°çŸ¥è¯†åº“2
                print(f"ğŸ“¤ ä¸Šä¼ æ‘˜è¦åˆ°æ‘˜è¦çŸ¥è¯†åº“ï¼ˆæ–‡æ¡£ID: {doc_id}ï¼‰...")
                summary_success = self.upload_summary_to_knowledge_base(summary, doc_id, workspace_id, summary_index_id)
                
                if summary_success:
                    print(f"âœ… æ–‡ä»¶ {file_name} å¤„ç†å®Œæˆ")
                    results.append({
                        "file": file_name,
                        "status": "success",
                        "doc_id": doc_id
                    })
                else:
                    print(f"âŒ æ–‡ä»¶ {file_name} æ‘˜è¦ä¸Šä¼ å¤±è´¥")
                    results.append({
                        "file": file_name,
                        "status": "summary_upload_failed",
                        "doc_id": doc_id
                    })
            else:
                print(f"âŒ æ–‡ä»¶ {file_name} åŸæ–‡ä¸Šä¼ å¤±è´¥")
                results.append({
                    "file": file_name,
                    "status": "original_upload_failed"
                })
        
        success_count = len([r for r in results if r["status"] == "success"])
        return {
            "success": True,
            "message": f"å¤„ç†å®Œæˆï¼ŒæˆåŠŸ: {success_count}/{len(all_files)}",
            "results": results
        }

if __name__ == '__main__':
    # é…ç½®å‚æ•°
    directory_path = "./input_files"  # æ–‡æ¡£ç›®å½•è·¯å¾„
    workspace_id = os.environ.get('WORKSPACE_ID')  # å·¥ä½œç©ºé—´ID
    original_index_id = os.environ.get("BAILIAN_ORIGINAL_DATASET_ID")  # åŸæ–‡çŸ¥è¯†åº“ID
    summary_index_id = os.environ.get("BAILIAN_SUMMARY_DATASET_ID")  # æ‘˜è¦çŸ¥è¯†åº“ID
    
    # åˆ›å»ºä¸Šä¼ å™¨å¹¶æ‰§è¡Œæ‰¹é‡ä¸Šä¼ 
    uploader = EnhancedUploader()
    result = uploader.batch_upload_with_summary(directory_path, workspace_id, original_index_id, summary_index_id)
    
    # è¾“å‡ºç»“æœ
    if result.get("success"):
        print(f"\n{result['message']}")
        for r in result['results']:
            status_icon = "âœ…" if r['status'] == 'success' else "âŒ"
            print(f"{status_icon} {r['file']}: {r['status']}")
    else:
        print(f"\næ‰¹é‡ä¸Šä¼ å¤±è´¥: {result.get('error')}")