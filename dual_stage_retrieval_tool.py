import os
from typing import Dict, Any, Optional, List
from langchain_core.tools import tool
from alibabacloud_bailian20231229 import models as bailian_20231229_models
from alibabacloud_bailian20231229.client import Client as bailian20231229Client
from alibabacloud_tea_openapi import models as open_api_models
from alibabacloud_tea_util import models as util_models
from langchain_core.tools import tool
from dotenv import load_dotenv

load_dotenv()

# é˜¿é‡Œäº‘ç™¾ç‚¼é…ç½®å¸¸é‡
WORKSPACE_ID = os.environ.get('WORKSPACE_ID', '')
SUMMARY_INDEX_ID = os.environ.get('BAILIAN_SUMMARY_DATASET_ID', '')  # æ‘˜è¦çŸ¥è¯†åº“ID
ORIGINAL_INDEX_ID = os.environ.get('BAILIAN_ORIGINAL_DATASET_ID', '')  # åŸæ–‡çŸ¥è¯†åº“ID

def create_bailian_client() -> bailian20231229Client:
    """åˆ›å»ºé˜¿é‡Œäº‘ç™¾ç‚¼å®¢æˆ·ç«¯"""
    config = open_api_models.Config(
        access_key_id=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_ID'),
        access_key_secret=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_SECRET')
    )
    config.endpoint = 'bailian.cn-beijing.aliyuncs.com'
    return bailian20231229Client(config)

def retrieve_index(client, workspace_id, index_id, query):
    """
    åœ¨æŒ‡å®šçš„çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ã€‚
        
    å‚æ•°:
        client (bailian20231229Client): å®¢æˆ·ç«¯ï¼ˆClientï¼‰ã€‚
        workspace_id (str): ä¸šåŠ¡ç©ºé—´IDã€‚
        index_id (str): çŸ¥è¯†åº“IDã€‚
        query (str): åŸå§‹è¾“å…¥promptã€‚

    è¿”å›:
        é˜¿é‡Œäº‘ç™¾ç‚¼æœåŠ¡çš„å“åº”ã€‚
    """
    headers = {}
    retrieve_request = bailian_20231229_models.RetrieveRequest(
        index_id=index_id,
        query=query
    )
    runtime = util_models.RuntimeOptions()
    return client.retrieve_with_options(workspace_id, retrieve_request, headers, runtime)

def list_index_documents(client, workspace_id, index_id, document_name=None):
    """
    è·å–æŒ‡å®šçŸ¥è¯†åº“ä¸­ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯ã€‚

    å‚æ•°:
        client (bailian20231229Client): å®¢æˆ·ç«¯ï¼ˆClientï¼‰ã€‚
        workspace_id (str): ä¸šåŠ¡ç©ºé—´IDã€‚
        index_id (str): çŸ¥è¯†åº“IDã€‚
        document_name (str, optional): æ–‡æ¡£åç§°ï¼Œç”¨äºè¿‡æ»¤ã€‚

    è¿”å›:
        é˜¿é‡Œäº‘ç™¾ç‚¼æœåŠ¡çš„å“åº”ã€‚
    """
    headers = {}
    list_index_documents_request = bailian_20231229_models.ListIndexDocumentsRequest(
        index_id=index_id,
        document_name=document_name
    )
    runtime = util_models.RuntimeOptions()
    return client.list_index_documents_with_options(workspace_id, list_index_documents_request, headers, runtime)

def extract_document_ids_from_summary_results(nodes: List) -> List[str]:
    """
    ä»æ‘˜è¦æ£€ç´¢ç»“æœä¸­æå–æ–‡æ¡£IDï¼ˆæ‘˜è¦æ–‡ä»¶åå»æ‰.mdåç¼€ï¼‰
    
    å‚æ•°:
        nodes: æ£€ç´¢ç»“æœèŠ‚ç‚¹åˆ—è¡¨
        
    è¿”å›:
        List[str]: æå–åˆ°çš„æ–‡æ¡£IDåˆ—è¡¨
    """
    document_ids = []
    
    for node in nodes:
        # å°è¯•ä»å…ƒæ•°æ®ä¸­è·å–æ–‡æ¡£åç§°
        metadata = getattr(node, 'metadata', {}) if hasattr(node, 'metadata') else {}
        
        # æ£€æŸ¥å…ƒæ•°æ®ä¸­æ˜¯å¦æœ‰document_nameå­—æ®µ
        if isinstance(metadata, dict):
            document_name = metadata.get('document_name') or metadata.get('doc_name') or metadata.get('file_name')
            if document_name:
                # ä»æ–‡æ¡£åç§°ä¸­æå–æ–‡æ¡£IDï¼ˆå»æ‰.mdåç¼€ï¼‰
                if document_name.endswith('.md'):
                    doc_id = document_name[:-3]  # å»æ‰.mdåç¼€
                    if doc_id and doc_id not in document_ids:
                        document_ids.append(doc_id)
                else:
                    # å¦‚æœä¸æ˜¯.mdæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                    if document_name not in document_ids:
                        document_ids.append(document_name)
        
        # å¦‚æœå…ƒæ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»å…¶ä»–å¯èƒ½çš„å­—æ®µè·å–
        if not document_ids:
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½åŒ…å«æ–‡æ¡£åçš„å­—æ®µ
            for field_name in ['title', 'filename', 'name']:
                field_value = metadata.get(field_name)
                if field_value and field_value.endswith('.md'):
                    doc_id = field_value[:-3]
                    if doc_id and doc_id not in document_ids:
                        document_ids.append(doc_id)
                    break
        
    return document_ids

def retrieve_full_document_by_id(client, workspace_id, index_id, document_id: str) -> Optional[str]:
    """
    é€šè¿‡æ–‡æ¡£IDä»åŸæ–‡çŸ¥è¯†åº“ä¸­æ£€ç´¢å®Œæ•´æ–‡æ¡£å†…å®¹ï¼Œä½¿ç”¨ç²¾ç¡®åŒ¹é…
    """
    headers = {}
    
    # æ„å»ºå…ƒæ•°æ®è¿‡æ»¤å™¨ï¼Œç²¾ç¡®åŒ¹é…doc_idå­—æ®µ
    search_filters = [{
        "doc_id": document_id  # ç²¾ç¡®åŒ¹é…ï¼Œä¸ä½¿ç”¨like
    }]
    
    retrieve_request = bailian_20231229_models.RetrieveRequest(
        index_id=index_id,
        query=document_id,  # ä½¿ç”¨æ–‡æ¡£IDä½œä¸ºæŸ¥è¯¢è¯
        search_filters=search_filters
    )
    
    runtime = util_models.RuntimeOptions()
    response = client.retrieve_with_options(workspace_id, retrieve_request, headers, runtime)
    
    if response.status_code == 200 and hasattr(response.body, 'data'):
        nodes = response.body.data.nodes if hasattr(response.body.data, 'nodes') else []
        if nodes:
            # æå–æ‰€æœ‰åŒ¹é…æ–‡æ¡£çš„æ–‡æœ¬å†…å®¹
            full_content = []
            for node in nodes:
                text = getattr(node, 'text', '') if hasattr(node, 'text') else ''
                if text.strip():
                    # è¿‡æ»¤æ‰å…ƒæ•°æ®ä¿¡æ¯ï¼Œåªä¿ç•™çº¯æ–‡æœ¬
                    lines = text.split('\n')
                    clean_lines = []
                    for line in lines:
                        if not (line.strip().startswith('ğŸ“‹ å…ƒæ•°æ®:') or 
                               line.strip().startswith('å…ƒæ•°æ®:') or
                               line.strip().startswith('æ–‡æ¡£ID:') or
                               line.strip().startswith('æ¥æº:')):
                            clean_lines.append(line)
                    
                    clean_text = '\n'.join(clean_lines).strip()
                    if clean_text:
                        full_content.append(clean_text)
            
            if full_content:
                return '\n\n'.join(full_content)
    
    return None
    
@tool
def dual_stage_retrieve(query: str, workspace_id: str = None, summary_index_id: str = None, 
                       original_index_id: str = None, top_k: int = 3) -> str:
    """
    åŒé˜¶æ®µæ£€ç´¢å·¥å…·ï¼šå…ˆä»æ‘˜è¦çŸ¥è¯†åº“æ£€ç´¢ï¼Œå†ä»åŸæ–‡çŸ¥è¯†åº“è·å–å®Œæ•´æ¡ˆä¾‹ã€‚
    
    è¿™ä¸ªå·¥å…·å®ç°ä¸¤é˜¶æ®µæ£€ç´¢ç­–ç•¥ï¼š
    1. ç¬¬ä¸€é˜¶æ®µï¼šåœ¨æ‘˜è¦çŸ¥è¯†åº“ä¸­æ£€ç´¢åŒ¹é…çš„æ‘˜è¦æ®µè½
    2. ç¬¬äºŒé˜¶æ®µï¼šæå–æ‘˜è¦æ–‡ä»¶åï¼ˆå³åŸæ–‡æ¡£IDï¼‰ï¼Œä»åŸæ–‡çŸ¥è¯†åº“ä¸­æ£€ç´¢å®Œæ•´æ¡ˆä¾‹å†…å®¹
    
    é€‚ç”¨äºéœ€è¦å…ˆé€šè¿‡æ‘˜è¦å¿«é€Ÿå®šä½ç›¸å…³æ¡ˆä¾‹ï¼Œå†è·å–å®Œæ•´è¯¦ç»†å†…å®¹çš„åœºæ™¯ã€‚
    
    Args:
        query (str): è¦æ£€ç´¢çš„æŸ¥è¯¢æ–‡æœ¬ï¼Œä¾‹å¦‚ "ç”Ÿæ€å†œä¸šæŠ€æœ¯åº”ç”¨"
        workspace_id (str, optional): é˜¿é‡Œäº‘ç™¾ç‚¼ä¸šåŠ¡ç©ºé—´IDï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡WORKSPACE_ID
        summary_index_id (str, optional): æ‘˜è¦çŸ¥è¯†åº“IDï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡BAILIAN_SUMMARY_DATASET_ID
        original_index_id (str, optional): åŸæ–‡çŸ¥è¯†åº“IDï¼Œé»˜è®¤ä½¿ç”¨ç¯å¢ƒå˜é‡BAILIAN_ORIGINAL_DATASET_ID
        top_k (int, optional): è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º3
        
    Returns:
        str: æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœï¼ŒåŒ…å«æ‘˜è¦åŒ¹é…ä¿¡æ¯å’Œå®Œæ•´æ¡ˆä¾‹å†…å®¹
        
    Example:
        >>> result = dual_stage_retrieve("å¯æŒç»­å†œä¸šå‘å±•æ¨¡å¼")
        >>> print(result)
        ğŸ” åŒé˜¶æ®µæ£€ç´¢ç»“æœ:
        - æŸ¥è¯¢: å¯æŒç»­å†œä¸šå‘å±•æ¨¡å¼
        - æ‘˜è¦çŸ¥è¯†åº“: xxx
        - åŸæ–‡çŸ¥è¯†åº“: xxx
        
        ğŸ“‹ ç¬¬ä¸€é˜¶æ®µ - æ‘˜è¦æ£€ç´¢ç»“æœ:
        æ‰¾åˆ° 2 ä¸ªç›¸å…³æ‘˜è¦
        
        ğŸ“š ç¬¬äºŒé˜¶æ®µ - å®Œæ•´æ¡ˆä¾‹å†…å®¹:
        [å®Œæ•´æ¡ˆä¾‹1]
        [å®Œæ•´æ¡ˆä¾‹2]
    """
    
    # ä½¿ç”¨ä¼ å…¥å‚æ•°æˆ–ç¯å¢ƒå˜é‡
    ws_id = workspace_id or WORKSPACE_ID
    summary_idx_id = summary_index_id or SUMMARY_INDEX_ID
    original_idx_id = original_index_id or ORIGINAL_INDEX_ID
    
    if not ws_id or not summary_idx_id or not original_idx_id:
        return "âŒ é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„é…ç½®å‚æ•°ã€‚è¯·è®¾ç½® WORKSPACE_IDã€BAILIAN_SUMMARY_DATASET_ID å’Œ BAILIAN_ORIGINAL_DATASET_ID ç¯å¢ƒå˜é‡ï¼Œæˆ–åœ¨è°ƒç”¨æ—¶ä¼ å…¥å‚æ•°ã€‚"
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = create_bailian_client()
    
    try:
        # ç¬¬ä¸€é˜¶æ®µï¼šä»æ‘˜è¦çŸ¥è¯†åº“æ£€ç´¢
        print(f"ğŸ” ç¬¬ä¸€é˜¶æ®µï¼šåœ¨æ‘˜è¦çŸ¥è¯†åº“ä¸­æ£€ç´¢ '{query}'...")
        summary_result = retrieve_index(client, ws_id, summary_idx_id, query)
        
        if not summary_result or not hasattr(summary_result, 'body'):
            return f"âŒ ç¬¬ä¸€é˜¶æ®µæ£€ç´¢å¤±è´¥ï¼šæ— æ³•ä»æ‘˜è¦çŸ¥è¯†åº“ä¸­è·å–ç›¸å…³ä¿¡æ¯"
        
        # è§£ææ‘˜è¦æ£€ç´¢ç»“æœ
        summary_nodes = summary_result.body.data.nodes if hasattr(summary_result.body.data, 'nodes') else []
        
        if not summary_nodes:
            return f"ğŸ” åŒé˜¶æ®µæ£€ç´¢ç»“æœ:\n- æŸ¥è¯¢: {query}\n- æ‘˜è¦çŸ¥è¯†åº“: {summary_idx_id}\n- æ£€ç´¢ç»“æœ: æœªæ‰¾åˆ°ç›¸å…³æ‘˜è¦"
        
        # æå–æ–‡æ¡£ID
        document_ids = extract_document_ids_from_summary_results(summary_nodes[:top_k])
        
        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        result_lines = [
            f"ğŸ” åŒé˜¶æ®µæ£€ç´¢ç»“æœ:",
            f"- æŸ¥è¯¢: {query}",
            f"- æ‘˜è¦çŸ¥è¯†åº“: {summary_idx_id}",
            f"- åŸæ–‡çŸ¥è¯†åº“: {original_idx_id}",
            "",
            f"ğŸ“‹ ç¬¬ä¸€é˜¶æ®µ - æ‘˜è¦æ£€ç´¢ç»“æœ:",
            f"æ‰¾åˆ° {len(summary_nodes)} ä¸ªç›¸å…³æ‘˜è¦"
        ]
        
        # æ˜¾ç¤ºæ‘˜è¦å†…å®¹
        for i, node in enumerate(summary_nodes[:top_k], 1):
            score = getattr(node, 'score', 0) if hasattr(node, 'score') else 0
            text = getattr(node, 'text', '') if hasattr(node, 'text') else ''
            
            result_lines.extend([
                f"\n{'-'*40}",
                f"æ‘˜è¦ {i} (ç›¸å…³åº¦: {score:.3f}):",
                f"{'-'*40}",
                text.strip()[:200] + "..." if len(text.strip()) > 200 else text.strip()
            ])

        print('\n'.join(result_lines))
        result_lines=[]

        # ä½¿ç”¨æå–çš„æ–‡æ¡£IDæ£€ç´¢å®Œæ•´å†…å®¹
        print(f"ğŸ“š ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨æ–‡æ¡£ID {document_ids} æ£€ç´¢å®Œæ•´æ¡ˆä¾‹...")
        
        full_cases_found = 0
        for i, doc_id in enumerate(document_ids[:top_k], 1):
            print(f"  æ­£åœ¨æ£€ç´¢æ–‡æ¡£ID: {doc_id}")
            full_content = retrieve_full_document_by_id(client, ws_id, original_idx_id, doc_id)
            
            if full_content:
                result_lines.extend([
                    f"\n{'='*50}",
                    f"å®Œæ•´æ¡ˆä¾‹ {i} (æ–‡æ¡£ID: {doc_id}):",
                    f"{'='*50}",
                    full_content
                ])
                full_cases_found += 1
            else:
                result_lines.extend([
                    f"\nâš ï¸ æ–‡æ¡£ID {doc_id} å¯¹åº”çš„å®Œæ•´æ¡ˆä¾‹æœªæ‰¾åˆ°"
                ])
        
        if full_cases_found == 0:
            result_lines.append("\nâŒ æœªèƒ½æ£€ç´¢åˆ°ä»»ä½•å®Œæ•´æ¡ˆä¾‹å†…å®¹")
        else:
            result_lines.insert(-full_cases_found*4-1, f"\nâœ… æˆåŠŸæ£€ç´¢åˆ° {full_cases_found} ä¸ªå®Œæ•´æ¡ˆä¾‹")
        
        return '\n'.join(result_lines)
        
    except Exception as e:
        return f"âŒ åŒé˜¶æ®µæ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

if __name__ == "__main__":
    # æµ‹è¯•åŒé˜¶æ®µæ£€ç´¢åŠŸèƒ½
    test_query = "ç”Ÿæ€å†œä¸šå¯æŒç»­å‘å±•"
    print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
    print(f"{'='*80}")
    result = dual_stage_retrieve.invoke({"query": test_query})
    print(result)