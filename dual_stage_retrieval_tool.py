import os
from typing import Dict, Any, Optional, List
from langchain_core.tools import tool
from alibabacloud_bailian20231229 import models as bailian_20231229_models
from alibabacloud_bailian20231229.client import Client as bailian20231229Client
from alibabacloud_tea_openapi import models as open_api_models
from alibabacloud_tea_util import models as util_models
from langchain_core.tools import tool
from dotenv import load_dotenv

load_dotenv()

# é˜¿é‡Œäº‘ç™¾ç‚¼é…ç½®å¸¸é‡
WORKSPACE_ID = os.environ.get('WORKSPACE_ID', '')
SUMMARY_INDEX_ID = os.environ.get('BAILIAN_SUMMARY_DATASET_ID', '')  # æ‘˜è¦çŸ¥è¯†åº“ID
ORIGINAL_INDEX_ID = os.environ.get('BAILIAN_ORIGINAL_DATASET_ID', '')  # åŸæ–‡çŸ¥è¯†åº“ID

def create_bailian_client() -> bailian20231229Client:
    """åˆ›å»ºé˜¿é‡Œäº‘ç™¾ç‚¼å®¢æˆ·ç«¯"""
    config = open_api_models.Config(
        access_key_id=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_ID', ''),
        access_key_secret=os.environ.get('ALIBABA_CLOUD_ACCESS_KEY_SECRET', '')
    )
    config.endpoint = 'bailian.cn-beijing.aliyuncs.com'
    return bailian20231229Client(config)

def retrieve_index(client, workspace_id, index_id, query):
    """
    åœ¨æŒ‡å®šçš„çŸ¥è¯†åº“ä¸­æ£€ç´¢ä¿¡æ¯ã€‚
        
    å‚æ•°:
        client (bailian20231229Client): å®¢æˆ·ç«¯ï¼ˆClientï¼‰ã€‚
        workspace_id (str): ä¸šåŠ¡ç©ºé—´IDã€‚
        index_id (str): çŸ¥è¯†åº“IDã€‚
        query (str): åŸå§‹è¾“å…¥promptã€‚

    è¿”å›:
        é˜¿é‡Œäº‘ç™¾ç‚¼æœåŠ¡çš„å“åº”ã€‚
    """
    headers = {}
    retrieve_request = bailian_20231229_models.RetrieveRequest(
        index_id=index_id,
        query=query
    )
    runtime = util_models.RuntimeOptions()
    return client.retrieve_with_options(workspace_id, retrieve_request, headers, runtime)

def list_index_documents(client, workspace_id, index_id, document_name=None):
    """
    è·å–æŒ‡å®šçŸ¥è¯†åº“ä¸­ä¸€ä¸ªæˆ–å¤šä¸ªæ–‡æ¡£çš„è¯¦ç»†ä¿¡æ¯ã€‚

    å‚æ•°:
        client (bailian20231229Client): å®¢æˆ·ç«¯ï¼ˆClientï¼‰ã€‚
        workspace_id (str): ä¸šåŠ¡ç©ºé—´IDã€‚
        index_id (str): çŸ¥è¯†åº“IDã€‚
        document_name (str, optional): æ–‡æ¡£åç§°ï¼Œç”¨äºè¿‡æ»¤ã€‚

    è¿”å›:
        é˜¿é‡Œäº‘ç™¾ç‚¼æœåŠ¡çš„å“åº”ã€‚
    """
    headers = {}
    # åˆ›å»ºè¯·æ±‚å¯¹è±¡ï¼Œåªæœ‰å½“document_nameä¸ä¸ºNoneæ—¶æ‰ä¼ é€’è¯¥å‚æ•°
    if document_name is not None:
        list_index_documents_request = bailian_20231229_models.ListIndexDocumentsRequest(
            index_id=index_id,
            document_name=document_name
        )
    else:
        list_index_documents_request = bailian_20231229_models.ListIndexDocumentsRequest(
            index_id=index_id
        )
    runtime = util_models.RuntimeOptions()
    return client.list_index_documents_with_options(workspace_id, list_index_documents_request, headers, runtime)

def extract_document_ids_from_summary_results(nodes: List) -> List[str]:
    """
    ä»æ‘˜è¦æ£€ç´¢ç»“æœä¸­æå–æ–‡æ¡£IDï¼ˆæ‘˜è¦æ–‡ä»¶åå»æ‰.mdåç¼€ï¼‰
    
    å‚æ•°:
        nodes: æ£€ç´¢ç»“æœèŠ‚ç‚¹åˆ—è¡¨
        
    è¿”å›:
        List[str]: æå–åˆ°çš„æ–‡æ¡£IDåˆ—è¡¨
    """
    document_ids = []
    
    for node in nodes:
        # å°è¯•ä»å…ƒæ•°æ®ä¸­è·å–æ–‡æ¡£åç§°
        metadata = getattr(node, 'metadata', {}) if hasattr(node, 'metadata') else {}
        
        # æ£€æŸ¥å…ƒæ•°æ®ä¸­æ˜¯å¦æœ‰document_nameå­—æ®µ
        if isinstance(metadata, dict):
            document_name = metadata.get('document_name') or metadata.get('doc_name') or metadata.get('file_name')
            if document_name:
                # ä»æ–‡æ¡£åç§°ä¸­æå–æ–‡æ¡£IDï¼ˆå»æ‰.mdåç¼€ï¼‰
                if document_name.endswith('.md'):
                    doc_id = document_name[:-3]  # å»æ‰.mdåç¼€
                    if doc_id and doc_id not in document_ids:
                        document_ids.append(doc_id)
                else:
                    # å¦‚æœä¸æ˜¯.mdæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                    if document_name not in document_ids:
                        document_ids.append(document_name)
        
        # å¦‚æœå…ƒæ•°æ®ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»å…¶ä»–å¯èƒ½çš„å­—æ®µè·å–
        if not document_ids:
            # æ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å¯èƒ½åŒ…å«æ–‡æ¡£åçš„å­—æ®µ
            for field_name in ['title', 'filename', 'name']:
                field_value = metadata.get(field_name)
                if field_value and field_value.endswith('.md'):
                    doc_id = field_value[:-3]
                    if doc_id and doc_id not in document_ids:
                        document_ids.append(doc_id)
                    break
        
    return document_ids

def retrieve_full_document_by_id(client, workspace_id, index_id, document_id: str) -> Optional[str]:
    """
    é€šè¿‡æ–‡æ¡£IDä»åŸæ–‡çŸ¥è¯†åº“ä¸­æ£€ç´¢å®Œæ•´æ–‡æ¡£å†…å®¹ï¼Œä½¿ç”¨ç²¾ç¡®åŒ¹é…ï¼ŒæŒ‰å­˜å‚¨é¡ºåºè¿”å›
    """
    headers = {}
    
    # æ„å»ºå…ƒæ•°æ®è¿‡æ»¤å™¨ï¼Œç²¾ç¡®åŒ¹é…doc_idå­—æ®µ
    search_filters = [{
        "doc_id": document_id  # ç²¾ç¡®åŒ¹é…ï¼Œä¸ä½¿ç”¨like
    }]
    
    retrieve_request = bailian_20231229_models.RetrieveRequest(
        index_id=index_id,
        query=document_id,  # ä½¿ç”¨æ–‡æ¡£IDä½œä¸ºæŸ¥è¯¢è¯
        search_filters=search_filters
    )
    
    runtime = util_models.RuntimeOptions()
    response = client.retrieve_with_options(workspace_id, retrieve_request, headers, runtime)
    
    if response.status_code == 200 and hasattr(response.body, 'data'):
        nodes = response.body.data.nodes if hasattr(response.body.data, 'nodes') else []
        if nodes:
            # å®šä¹‰æ’åºå‡½æ•°ï¼Œä»_idä¸­æå–æ•°å­—ç´¢å¼•
            def get_sort_key(node):
                # å°è¯•ä»å…ƒæ•°æ®ä¸­è·å–_id
                metadata = getattr(node, 'metadata', {}) if hasattr(node, 'metadata') else {}
                if isinstance(metadata, dict):
                    node_id = metadata.get('_id', '')
                    if node_id:
                        # ä»_idæœ«å°¾æå–æ•°å­—éƒ¨åˆ†ï¼Œæ ¼å¼: {å‰ç¼€}_{chunk_index}_{sub_index}
                        parts = node_id.split('_')
                        if len(parts) >= 2:
                            try:
                                # å–æœ€åä¸¤ä¸ªæ•°å­—éƒ¨åˆ†ä½œä¸ºæ’åºé”®
                                chunk_index = int(parts[-2]) if parts[-2].isdigit() else 0
                                sub_index = int(parts[-1]) if parts[-1].isdigit() else 0
                                return (chunk_index, sub_index)
                            except (ValueError, IndexError):
                                pass
                
                # å¦‚æœæ— æ³•ä»_idæå–ï¼Œå°è¯•å…¶ä»–å­—æ®µ
                if isinstance(metadata, dict):
                    page_number = metadata.get('page_number')
                    if page_number is not None:
                        try:
                            return (int(page_number), 0)
                        except (ValueError, TypeError):
                            pass
                
                # é»˜è®¤è¿”å›(0, 0)
                return (0, 0)
            
            # æŒ‰ç…§æå–çš„ç´¢å¼•è¿›è¡Œæ’åº
            nodes = sorted(nodes, key=get_sort_key)
            
            # æå–æ‰€æœ‰åŒ¹é…æ–‡æ¡£çš„æ–‡æœ¬å†…å®¹
            full_content = []
            for node in nodes:
                text = getattr(node, 'text', '') if hasattr(node, 'text') else ''
                if text.strip():
                    # è¿‡æ»¤æ‰å…ƒæ•°æ®ä¿¡æ¯ï¼Œåªä¿ç•™çº¯æ–‡æœ¬
                    lines = text.split('\n')
                    clean_lines = []
                    for line in lines:
                        if not (line.strip().startswith('ğŸ“‹ å…ƒæ•°æ®:') or 
                               line.strip().startswith('å…ƒæ•°æ®:') or
                               line.strip().startswith('æ–‡æ¡£ID:') or
                               line.strip().startswith('æ¥æº:')):
                            clean_lines.append(line)
                    
                    clean_text = '\n'.join(clean_lines).strip()
                    if clean_text:
                        full_content.append(clean_text)
            
            if full_content:
                return '\n\n'.join(full_content)
    
    return None
    
@tool
def dual_stage_retrieve(query: str, top_k: int = 3) -> str:
    """
    ä¹¡æ‘æŒ¯å…´æ¡ˆä¾‹åŒé˜¶æ®µæ£€ç´¢å·¥å…·ï¼šå…ˆä»æ‘˜è¦åº“æ£€ç´¢ï¼Œå†è·å–å®Œæ•´æ¡ˆä¾‹ã€‚
    
    è¿™ä¸ªå·¥å…·ä¸“é—¨ç”¨äºæ£€ç´¢ä¹¡æ‘æŒ¯å…´ç›¸å…³æ¡ˆä¾‹ä¿¡æ¯ï¼š
    1. ç¬¬ä¸€é˜¶æ®µï¼šåœ¨æ‘˜è¦çŸ¥è¯†åº“ä¸­æ£€ç´¢åŒ¹é…çš„æ¡ˆä¾‹æ‘˜è¦
    2. ç¬¬äºŒé˜¶æ®µï¼šè·å–å®Œæ•´çš„æ¡ˆä¾‹è¯¦ç»†å†…å®¹
    
    é€‚ç”¨äºæŸ¥è¯¢ä¹¡æ‘æŒ¯å…´ã€å†œä¸šå‘å±•ã€äº§ä¸šåŒ–ç»è¥ç­‰ç›¸å…³æ¡ˆä¾‹ã€‚
    
    Args:
        query (str): æ£€ç´¢å…³é”®è¯ï¼Œå»ºè®®ä½¿ç”¨3-5ä¸ªæ ¸å¿ƒå…³é”®è¯ï¼Œå¦‚"ç”Ÿæ€å†œä¸š äº§ä¸šåŒ–"
        top_k (int, optional): è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡ï¼Œé»˜è®¤ä¸º3
        
    Returns:
        str: æ ¼å¼åŒ–çš„æ£€ç´¢ç»“æœï¼ŒåŒ…å«ç›¸å…³æ¡ˆä¾‹çš„å®Œæ•´å†…å®¹
        
    Example:
        >>> result = dual_stage_retrieve("ç”Ÿæ€å†œä¸š å¯æŒç»­æ€§")
        >>> result = dual_stage_retrieve("ä¹¡æ‘æ—…æ¸¸ äº§ä¸šèåˆ")
        >>> result = dual_stage_retrieve("åˆä½œç¤¾ ç»è¥æ¨¡å¼")
    """
    
    # ç›´æ¥ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼Œä¸å†ä½œä¸ºå‚æ•°
    ws_id = WORKSPACE_ID
    summary_idx_id = SUMMARY_INDEX_ID
    original_idx_id = ORIGINAL_INDEX_ID
    
    if not ws_id or not summary_idx_id or not original_idx_id:
        return "âŒ é”™è¯¯ï¼šçŸ¥è¯†åº“é…ç½®ç¼ºå¤±ã€‚è¯·æ£€æŸ¥ç¯å¢ƒå˜é‡é…ç½®ã€‚"
    
    # åˆ›å»ºå®¢æˆ·ç«¯
    client = create_bailian_client()
    
    try:
        # ç¬¬ä¸€é˜¶æ®µï¼šä»æ‘˜è¦çŸ¥è¯†åº“æ£€ç´¢
        print(f"ğŸ” ç¬¬ä¸€é˜¶æ®µï¼šåœ¨æ‘˜è¦çŸ¥è¯†åº“ä¸­æ£€ç´¢ '{query}'...")
        summary_result = retrieve_index(client, ws_id, summary_idx_id, query)
        
        if not summary_result or not hasattr(summary_result, 'body'):
            return f"âŒ ç¬¬ä¸€é˜¶æ®µæ£€ç´¢å¤±è´¥ï¼šæ— æ³•ä»æ‘˜è¦çŸ¥è¯†åº“ä¸­è·å–ç›¸å…³ä¿¡æ¯"
        
        # è§£ææ‘˜è¦æ£€ç´¢ç»“æœ
        summary_nodes = summary_result.body.data.nodes if hasattr(summary_result.body.data, 'nodes') else []
        
        if not summary_nodes:
            return f"ğŸ” åŒé˜¶æ®µæ£€ç´¢ç»“æœ:\n- æŸ¥è¯¢: {query}\n- æ‘˜è¦çŸ¥è¯†åº“: {summary_idx_id}\n- æ£€ç´¢ç»“æœ: æœªæ‰¾åˆ°ç›¸å…³æ‘˜è¦"
        
        # æå–æ–‡æ¡£ID
        document_ids = extract_document_ids_from_summary_results(summary_nodes[:top_k])
        
        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        result_lines = [
            f"ğŸ” åŒé˜¶æ®µæ£€ç´¢ç»“æœ:",
            f"- æŸ¥è¯¢: {query}",
            f"- æ‘˜è¦çŸ¥è¯†åº“: {summary_idx_id}",
            f"- åŸæ–‡çŸ¥è¯†åº“: {original_idx_id}",
            "",
            f"ğŸ“‹ ç¬¬ä¸€é˜¶æ®µ - æ‘˜è¦æ£€ç´¢ç»“æœ:",
            f"æ‰¾åˆ° {len(summary_nodes)} ä¸ªç›¸å…³æ‘˜è¦"
        ]
        
        # æ˜¾ç¤ºæ‘˜è¦å†…å®¹
        for i, node in enumerate(summary_nodes[:top_k], 1):
            score = getattr(node, 'score', 0) if hasattr(node, 'score') else 0
            text = getattr(node, 'text', '') if hasattr(node, 'text') else ''
            
            result_lines.extend([
                f"\n{'-'*40}",
                f"æ‘˜è¦ {i} (ç›¸å…³åº¦: {score:.3f}):",
                f"{'-'*40}",
                text.strip()[:200] + "..." if len(text.strip()) > 200 else text.strip()
            ])

        print('\n'.join(result_lines))
        result_lines=[]

        # ä½¿ç”¨æå–çš„æ–‡æ¡£IDæ£€ç´¢å®Œæ•´å†…å®¹
        print()
        print(f"ğŸ“š ç¬¬äºŒé˜¶æ®µï¼šä½¿ç”¨æ–‡æ¡£ID {document_ids} æ£€ç´¢å®Œæ•´æ¡ˆä¾‹...")
        
        full_cases_found = 0
        for i, doc_id in enumerate(document_ids[:top_k], 1):
            print(f"  æ­£åœ¨æ£€ç´¢æ–‡æ¡£ID: {doc_id}")
            full_content = retrieve_full_document_by_id(client, ws_id, original_idx_id, doc_id)
            
            if full_content:
                result_lines.extend([
                    f"\n{'='*50}",
                    f"å®Œæ•´æ¡ˆä¾‹ {i} (æ–‡æ¡£ID: {doc_id}):",
                    f"{'='*50}",
                    full_content
                ])
                full_cases_found += 1
            else:
                result_lines.extend([
                    f"\nâš ï¸ æ–‡æ¡£ID {doc_id} å¯¹åº”çš„å®Œæ•´æ¡ˆä¾‹æœªæ‰¾åˆ°"
                ])
        
        if full_cases_found == 0:
            result_lines.append("\nâŒ æœªèƒ½æ£€ç´¢åˆ°ä»»ä½•å®Œæ•´æ¡ˆä¾‹å†…å®¹")
        else:
            result_lines.insert(-full_cases_found*4-1, f"\nâœ… æˆåŠŸæ£€ç´¢åˆ° {full_cases_found} ä¸ªå®Œæ•´æ¡ˆä¾‹")
        
        return '\n'.join(result_lines)
        
    except Exception as e:
        return f"âŒ åŒé˜¶æ®µæ£€ç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

if __name__ == "__main__":
    # æµ‹è¯•åŒé˜¶æ®µæ£€ç´¢åŠŸèƒ½
    test_query = "ç”Ÿæ€å†œä¸šå¯æŒç»­æ€§æ¨¡å¼"
    print(f"æµ‹è¯•æŸ¥è¯¢: {test_query}")
    print(f"{'='*80}")
    result = dual_stage_retrieve.invoke({"query": test_query})
    print(result)