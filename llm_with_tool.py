import os
import asyncio
import json
from langchain_openai import ChatOpenAI
from langgraph.prebuilt import create_react_agent
from dotenv import load_dotenv
from filter import bailian_knowledge_retrieve


load_dotenv()

async def stream_with_token_output():
    llm = ChatOpenAI(
        model="google/gemini-2.5-flash",
        api_key=os.getenv('OPENROUTER_API_KEY'),
        base_url=os.getenv('OPENROUTER_BASE_URL', 'https://openrouter.ai/api/v1'),
        temperature=0.7,
        streaming=True
    )
    
    agent = create_react_agent(
        model=llm,
        tools=[bailian_knowledge_retrieve],
        prompt="""
        ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¹¡æ‘ç»è¥é¡¾é—®AIåŠ©æ‰‹ï¼Œæ‹¥æœ‰è®¿é—®ä¹¡æ‘ç»è¥çŸ¥è¯†åº“çš„èƒ½åŠ›ã€‚
        
        ## çŸ¥è¯†åº“å·¥å…·ä½¿ç”¨æŒ‡å—ï¼š
        
        ### æ ¸å¿ƒåŽŸåˆ™ï¼š
        1. **æç‚¼æ ¸å¿ƒé—®é¢˜**ï¼šä¸è¦å°†ç”¨æˆ·çš„å®Œæ•´é—®é¢˜ç›´æŽ¥ä¼ å…¥å·¥å…·ï¼Œè€Œæ˜¯æç‚¼å‡ºæ ¸å¿ƒå…³é”®è¯è¿›è¡Œæ£€ç´¢
        2. **å¤šæ¬¡æ£€ç´¢**ï¼šå¯ä»¥å¤šæ¬¡è°ƒç”¨å·¥å…·èŽ·å–æ›´å®Œæ•´çš„ä¿¡æ¯ï¼Œæ¯æ¬¡èšç„¦ä¸åŒè§’åº¦
        3. **åˆ©ç”¨å…ƒæ•°æ®è¿‡æ»¤**ï¼šå……åˆ†åˆ©ç”¨äº”ä¸ªå…ƒæ•°æ®å­—æ®µæé«˜æ£€ç´¢ç²¾å‡†åº¦
        
        ### æ£€ç´¢ç­–ç•¥ï¼š
        - å°†å¤æ‚é—®é¢˜æ‹†è§£ä¸ºå¤šä¸ªæ ¸å¿ƒæ¦‚å¿µåˆ†åˆ«æ£€ç´¢
        - å…ˆè¿›è¡Œå®½æ³›æ£€ç´¢ï¼Œå†æ ¹æ®ç»“æžœè¿›è¡Œç²¾å‡†æ£€ç´¢
        - æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©åˆé€‚çš„å…ƒæ•°æ®è¿‡æ»¤æ¡ä»¶
        
        ### äº”ä¸ªå…ƒæ•°æ®è¿‡æ»¤å­—æ®µï¼š
        1. **summary_keywords**: æ‘˜è¦å…³é”®è¯è¿‡æ»¤ - ç”¨äºŽç­›é€‰ç‰¹å®šä¸»é¢˜çš„æ¡ˆä¾‹
        2. **sustainable_operation**: å¯æŒç»­è¿è¥å…³é”®è¯ - ç­›é€‰å¯æŒç»­å‘å±•ç›¸å…³å†…å®¹
        3. **production_sales**: äº§é”€å…³é”®è¯ - ç­›é€‰ç”Ÿäº§é”€å”®ç›¸å…³æ¡ˆä¾‹
        4. **industry_keywords**: äº§ä¸šå…³é”®è¯ - æŒ‰äº§ä¸šç±»åž‹ç­›é€‰
        5. **resource_keywords**: èµ„æºå…³é”®è¯ - æŒ‰èµ„æºç±»åž‹ç­›é€‰
        
        ### ä½¿ç”¨ç¤ºä¾‹ï¼š
        - ç”¨æˆ·é—®"å¦‚ä½•å‘å±•ç”Ÿæ€å†œä¸š"ï¼Œåº”è¯¥ï¼š
          1. å…ˆæ£€ç´¢"ç”Ÿæ€å†œä¸š"èŽ·å–åŸºç¡€ä¿¡æ¯
          2. å†æ£€ç´¢"å¯æŒç»­å‘å±•"å¹¶ä½¿ç”¨sustainable_operationè¿‡æ»¤
          3. æœ€åŽæ£€ç´¢"å†œä¸šäº§ä¸šåŒ–"å¹¶ä½¿ç”¨industry_keywordsè¿‡æ»¤
        
        è®°ä½ï¼šå¤šè§’åº¦æ£€ç´¢æ¯”å•æ¬¡æ£€ç´¢æ›´èƒ½èŽ·å¾—å…¨é¢ä¿¡æ¯ï¼
        """
    )
    
    test_query = "è¯·å¸®æˆ‘æŸ¥è¯¢ç”Ÿæ€å†œä¸šç›¸å…³çš„ä¿¡æ¯"
    print(f"ðŸ¤– æŸ¥è¯¢: {test_query}")
    print("=" * 60)
    
    async for event in agent.astream_events(
        {"messages": [{"role": "user", "content": test_query}]},
        version="v1"
    ):
        event_type = event.get("event")
        
        if event_type == "on_chat_model_stream":
            chunk = event.get("data", {}).get("chunk", {})
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end="", flush=True)
                
        elif event_type == "on_tool_start":
            tool_name = event.get("name", "")
            tool_input = event.get("data", {}).get("input", {})
            print(f"\nðŸ”§ [{tool_name}] æ‰§è¡Œä¸­...")
            print(f"å‚æ•°: {json.dumps(tool_input, ensure_ascii=False)}")
            
        elif event_type == "on_tool_end":
            tool_name = event.get("name", "")
            tool_output = event.get("data", {}).get("output", "")
            print(f"\nâš¡ [{tool_name}] å®Œæˆ")
            
            output_content = tool_output.content if hasattr(tool_output, 'content') else str(tool_output)
            print(f"ç»“æžœ: {output_content[:100]}..." if len(output_content) > 100 else f"ç»“æžœ: {output_content}")

if __name__ == "__main__":
    asyncio.run(stream_with_token_output())